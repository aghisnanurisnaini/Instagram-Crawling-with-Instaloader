# -*- coding: utf-8 -*-
"""INSTAGRAM CRAWLING USING INSTALOADER

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10iGfnaL92sZHsJqyq4whDaI-PQCFCUSz
"""

!pip install instaloader

import pickle

# Enter manually retrieved cookie data from Inspect
cookies = {
    "datr": "your_datr",
    "csrftoken": "your_csrftoken",
    "sessionid": "your_sessionid",
    "ds_user_id": "your_ds_user_id",
    "mid": "your_mid",               # (Optional)
}

# Verify cookie data
for key, value in cookies.items():
    if not value:
        print(f"The cookie '{key}' is empty. Make sure all fields are filled correctly.")
        exit()

# Save cookies to a pickle file
pickle_file_path = "cookies.pkl"
try:
    with open(pickle_file_path, 'wb') as file:
        pickle.dump(cookies, file)
    print(f"Cookie is successfully stored in: {pickle_file_path}")
except Exception as e:
    print(f"Failed to save cookieClick to apply: {e}")

import instaloader
import pandas as pd
from instaloader import Post

# Instaloader Initialize
loader = instaloader.Instaloader()

pickle_file_path = "cookies.pkl"
username = "your_usn"

# Login using file cookie
try:
    with open(pickle_file_path, 'rb') as file:
        loader.context.load_session_from_file(username, file)
    print(f"Successful login using cookies for account: {username}")
except Exception as e:
    print(f"Failed login: {e}")
    exit()

# List of Instagram accounts you want to recap
accounts = [
    "nathantjoeaon", "thomhaye", "justinhubner5",  # you can add more
]

data = []

# Retrieve posts from each account
for account in accounts:
    try:
        print(f"Retrieve posts from: {account}")
        profile = instaloader.Profile.from_username(loader.context, account)

        for post in profile.get_posts():
            data.append({
                "Username": account,
                "Datetime": post.date.strftime("%Y-%m-%d %H:%M:%S"),
                "Description": post.caption or "Tidak ada deskripsi",
                "Link": f"https://www.instagram.com/p/{post.shortcode}/"
            })

    except Exception as e:
        print(f"failed to retrieve posts from {account}: {e}")

# Convert data to DataFrame
df = pd.DataFrame(data)

# save to excel
output_file = "crawling_data.xlsx"
try:
    df.to_excel(output_file, index=False)
    print(f"Data is successfully stored in: {output_file}")
except Exception as e:
    print(f"Failed to save the data to an Excel file: {e}")

from google.colab import files

# Download file
files.download("crawling_data.xlsx")